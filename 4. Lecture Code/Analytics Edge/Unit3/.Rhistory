geom_jitter(mapping = aes(x = displ, y = hwy))
ggplot(data = mpg) +
geom_boxplot(mapping = aes(x = class, y = hwy))
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
geom_boxplot() +
coord_flip()
nz <- map_data("nz")
ggplot(nz, aes(long, lat, group = group)) +
geom_polygon(fill = "white", colour = "black")
# coord_quickmap() sets the aspect ratio correctly for maps.
ggplot(nz, aes(long, lat, group = group)) +
geom_polygon(fill = "white", colour = "black") +
coord_quickmap()
bar <- ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, fill = cut),
show.legend = FALSE,
width = 1) +
theme(aspect.ratio = 1) +
labs(x = NULL, y = NULL)
bar
bar + coord_flip()
# coord_polar() uses polar coordinates.
bar + coord_polar()
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = clarity, fill = cut),
show.legend = FALSE,
width = 1) +
theme(aspect.ratio = 1) +
labs(x = NULL, y = NULL) +
coord_polar()
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_point() +
geom_abline() #+
#  coord_fixed()
ggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +
geom_point() +
geom_abline() +
coord_fixed()
install.packages("mlr")
install.packages("caret")
install.packages("caretEnsemble")
library(nycflights13)
library(tidyverse)
flights
filter(flights, month == 1, day == 1)
# A Tibble: 842 x 19
# Only assign to the variable
jan1 <- filter(flights, month == 1, day == 1)
# Assign and print the variable at the same time.
(dec25 <- filter(flights, month == 12, day == 25))
filter(flights, month = 1)
filter(flights, month == 1)
# filter(dataset, condition)
sqrt(2) ^ 2 == 2
#> [1] FALSE
1 / 49 * 49 == 1
#> [1] FALSE
sqrt(2) ^ 2 == 2
#> [1] FALSE
1 / 49 * 49 == 1
#> [1] FALSE
near(sqrt(2) ^ 2,  2)
#> [1] TRUE
near(1 / 49 * 49, 1)
#> [1] TRUE
filter(flights, month == 11 | month == 12)
filter(flights, month == 11 | month == 12)
filter(flights, month %in% c(11,12))
filter(flights, month in c(11,12))
filter(flights, month %in% c(11,12))
nov_dec <- filter(flights, month %in% c(11,12))
nov_dec
filter(flights, !(arr_delay > 120 | dep_delay > 120))
filter(flights, arr_delay <= 120, dep_delay <= 120)
#> [1] NA
#> [1] NA
NA + 10
#> [1] NA
10 == NA
#> [1] NA
NA + 10
#> [1] NA
NA / 2
#> [1] NA
#> [1] NA
NA / 2
```{r}
x <- NA
is.na(x)
df <- tibble(x = c(1, NA, 3))
filter(df, x > 1)
filter(df, is.na(x) | x > 1)
arrange(flights, year, month, day)
arragne(flights, desc(dep_delay))
arrange(flights, desc(dep_delay))
df <- tibble(x = c(5, 2, NA))
arrange(df, x)
#> # A tibble: 3 x 1
#>       x
#>   <dbl>
#> 1     2
#> 2     5
#> 3    NA
arrange(df, desc(x))
#> # A tibble: 3 x 1
#>       x
#>   <dbl>
#> 1     5
#> 2     2
#> 3    NA
select(flights, year, month, day)
# Select columns by name
select(flights, year, month, day)
# Select columns by range
select(flights, year:day)
# Select columns by name
select(flights, year, month, day)
# Select columns by range
select(flights, year:dep_delay)
# Select columns by name
select(flights, year, month, day)
# Select columns by range
select(flights, year:dep_delay)
# Select all columns except those specified
select(flights, -(year:dep_delay))
# Select columns by name
select(flights, year, month, day)
# Select columns by range
select(flights, year:dep_delay)
# Select all columns except those specified
select(flights, ~(year:dep_delay))
# Select columns by name
select(flights, year, month, day)
# Select columns by range
select(flights, year:dep_delay)
# Select all columns except those specified
select(flights, !(year:dep_delay))
# Select columns by name
select(flights, year, month, day)
# Select columns by range
select(flights, year:dep_delay)
# Select all columns except those specified
select(flights, -(year:dep_delay))
select(flights, contains('time'))
flights.columns
flights
rename(flights, tail_num = tailnum)
flights
rename(flights, test = tailnum)
select(flights, time_hour, day_time, everything())
select(flights, time_hour, air_time, everything())
flights_sml <- select(flights,
year:day,
ends_with("delay"),
distance,
air_time)
flights_sml
flights_sml <- select(flights,
year:day,
ends_with("delay"),
distance,
air_time)
flights_sml
mutate(flights_sml,
gain = dep_delay - arr_delay,
speed = distance / air_time * 60)
mutate(fights_sml,
gain = dep_depay - arr_delay,
hours = air_time / 60,
gain_per_hour = gain / hours)
mutate(flights_sml,
gain = dep_depay - arr_delay,
hours = air_time / 60,
gain_per_hour = gain / hours)
mutate(flights_sml,
gain = dep_delay - arr_delay,
hours = air_time / 60,
gain_per_hour = gain / hours)
transmute(flights,
gain = dep_delay - arr_delay,
hours = air_time / 60,
gain_per_hour = gain / hours)
transmute(flights,
dep_time,
hour = dep_time %/% 100,
minute = dep_time %% 100)
(x <- 1:10)
#>  [1]  1  2  3  4  5  6  7  8  9 10
lag(x)
#>  [1] NA  1  2  3  4  5  6  7  8  9
lead(x)
#>  [1]  2  3  4  5  6  7  8  9 10 NA
(x <- 1:10)
#>  [1]  1  2  3  4  5  6  7  8  9 10
lag(x)
#>  [1] NA  1  2  3  4  5  6  7  8  9
lead(x)
#>  [1]  2  3  4  5  6  7  8  9 10 NA
?lag
x
#>  [1]  1  2  3  4  5  6  7  8  9 10
cumsum(x)
#>  [1]  1  3  6 10 15 21 28 36 45 55
cummean(x)
#>  [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5
y <- c(1, 2, 2, NA, 3, r)
y <- c(1, 2, 2, NA, 3, 4)
min_rank(y)
min_rank(desc(y))
flights
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
(by_day <- group_by(flights, year, month, day))
summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))
(by_dest <- group_by(flights, dest))
(delay <- summarise(by_dest,
count = n(),
dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE)
))
(delay <- filter(delay, count > 20, dest != "HNL"))
# It looks like delays increase with distance up to ~750 miles
# and then decrease. Maybe as flights get longer there's more
# ability to make up delays in the air?
ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
geom_point(aes(size = count), alpha = 1/3) +
geom_smooth(se = FALSE)
# It looks like delays increase with distance up to ~750 miles
# and then decrease. Maybe as flights get longer there's more
# ability to make up delays in the air?
ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
geom_point(aes(size = count), alpha = 1/3) +
geom_smooth(se = TRUE)
delays <- flgihts %>%
group_by(dest) %>%
summarise(
count = n(),
dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE)
) %>%
filter(count > 20, dest !- "HNL")
delays <- flgihts %>%
group_by(dest) %>%
summarise(
count = n(),
dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE)
) %>%
filter(count > 20, dest != "HNL")
delays <- flights %>%
group_by(dest) %>%
summarise(
count = n(),
dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE)
) %>%
filter(count > 20, dest != "HNL")
(delays <- flights %>%
group_by(dest) %>%
summarise(
count = n(),
dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE)
) %>%
filter(count > 20, dest != "HNL"))
install.packages("ggvis")
install.packages("mice")
flights %>%
group_by(year, month, day) %>%
summarise(mean = mean(dep_delay))
flights %>%
group_by(year, month, day) %>%
summarise(mean = mean(dep_delay, na.rm = TRUE))
not_cancelled <- flights %>% filter(!is.na(dep_delay), !is.na(arr_delay)) # filter out those not_cancelled flights
not_cancelled %>%
group_by(year, month, day) %>%
summarise(mean = mean(dep_delay))
delays <- not_cancelled %>%
group_by(tailnum) %>%
summarise(
delay = mean(arr_delay)
)
ggplot(data = delays, mapping = aes(x = delay)) +
geom_freqpoly(binwidth = 10)
delays <- not_cancelled %>%
group_by(tailnum) %>%
summarise(
delay = mean(arr_delay, na.rm = TRUE),
n = n()
)
ggplot(data = delays, mapping = aes(x = n, y = delay)) +
geom_point(alpha = 1/10)
delays %>%
filter(n > 25) %>%
ggplot(mapping=aes(x = n, y = delay)) +
geom_point(alpha = 1/10)
delays %>%
filter(n > 25) %>%
ggplot(mapping=aes(x = n, y = delay)) +
geom_point(alpha = 1/10)
# Convert to a tibble so it prints nicely
batting <- as_tibble(Lahman::Batting)
batters <- batting %>%
group_by(playerID) %>%
summarise(
ba = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
ab = sum(AB, na.rm = TRUE)
)
batters %>%
filter(ab > 100) %>%
ggplot(mapping = aes(x = ab, y = ba)) +
geom_plot() +
geom_smooth(se = FALSE)
batters %>%
filter(ab > 100) %>%
ggplot(mapping = aes(x = ab, y = ba)) +
geom_point() +
geom_smooth(se = FALSE)
not_cancelled %>%
group_by(year, month, day) %>%
summarise(
avg_delay1 = mean(arr_delay),
avg_delay2 = mean(arr_delay[arr_delay > 0]) # the average positive delay
)
# Why is distance to some destinations more variable than to others?
not_cancelled %>%
group_by(dest) %>%
summarise(distance_sd = sd(distance)) %>%
arrange(desc(distance_sd))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(
first = min(dep_time),
last = max(dep_time)
)
not_cancelled %>%
group_by(year, month, day) %>%
summarise(
first_dep = first(dep_time),
last_dep = last(dep_time)
)
not_cancelled %>%
group_by(year, month, day) %>%
mutate(r = min_rank(desc(dep_time))) %>%
filter(r %in% range(r))
# Which destinations have the most carriers?
not_cancelled %>%
group_by(dest) %>%
summarise(carriers = n_distinct(carrier)) %>%
arrange(desc(carriers))
not_cancelled %>%
count(dest)
not_cancelled %>%
count(tailnum, wt = distance)
# How many flights left before 5am? (these usually indicate delayed
# flights from the previous day)
not_cancelled %>%
group_by(year, month day) %>%
# How many flights left before 5am? (these usually indicate delayed
# flights from the previous day)
not_cancelled %>%
group_by(year, month, day) %>%
summarise(n_early = sum(dep_time < 500))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(hour_prop = mean(arr_delay) > 60)
not_cancelled %>%
group_by(year, month, day) %>%
summarise(hour_prop = mean(arr_delay > 60))
(per_day <- summarise(daily, fights = n()))
daily <- group_by(flights, year, month, day)
(per_day <- summarise(daily, fights = n()))
install.packages("mice")
library(mice)
system("defaults write org.R-project.R force.LANG en_US.UTF-8")
Sys.setlocale("LC_ALL", "C")
8 * 6
2^15
2^16
8 * 10
sqrt(2)
abs(-10)
?sqrt
SquareRoot2 = sqrt(2)
SquareRoot2
ls()
setwd("~/_Course/AnalyticsEdge/Unit3")
quality = read.csv("quality.csv")
str(quality)
table(quality$PoorCare)
install.packages("caTools")
#install.packages("caTools")
library(caTools)
set.seed(88)
split = sample.split(quality$PoorCare, SplitRatio = 0.75)
qualityTrain - subset(quality, split == TRUE)
qualityTrain = subset(quality, split == TRUE)
qualityTest = subset(quality, split == FALSE)
QualityLog = glm(PoorCare ~ OfficeVisits + Narcotics, data = qualityTrain, family = binomial)
summary(QualityLog)
predictTrain = predict(QualityLog, type = "response")
?predict
summary(predictTrain)
tapply(predictTrain, qualityTrain$PoorCare, mean)
summary(glm(PoorCare ~ StartedOnCombination + ProviderCount, data = qualityTrain, family = binomial()))
table(qualityTrain$PoorCare, predictTrain > 0.5)
table(qualityTrain$PoorCare, predictTrain > 0.5)
table(qualityTrain$PoorCare, predictTrain > 0.7) # A confusion matrix for true outcome (rows) and predicted outcome (columns)
install.packages("ROCR")
# install.packages("ROCR")
library(ROCR)
ROCRpred = prediction(predictTrain, qualityTrain$PoorCare)
View(ROCRpred)
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf)
plot(ROCRperf, colorize = TRUE)
plot(ROCRperf, colorize = TRUE, print.cutoffs.at = seq(0,1,0.1), text.adj = c(-0.2, 1.7))
predictTest = predict(QualityLog, type = "response", newdata = qualityTest)
table(qualityTrain$PoorCare, predictTest > 0.3) # A confusion matrix for true outcome (rows) and predicted outcome (columns)
table(qualityTest$PoorCare, predictTest > 0.3) # A confusion matrix for true outcome (rows) and predicted outcome (columns)
# Let's compute the AUC score
ROCpredTest = prediction(predictTest, qualityTest$PoorCare)
auc = as.numeric(performance(ROCpredTest, "auc")@y.values)
auc
performance(ROCpredTest, "auc")
performance(ROCpredTest, "auc")@y
performance(ROCpredTest, "auc")@y.values
plot(performance(ROCpredTest, "tpr", "fpr"))
framingham = read.csv("framingham.csv")
str(framingham)
library(caTools)
set.seed(1000)
split = sample.split(framingham$TenYearCHD, SplitRatio = 0.65)
train = subset(framingham, split==TRUE)
test = subset(framingham, split==F)
framinghamLog = glm(TenYearCHD ~ ., data = train, family = binomial)
summary(framinghamLog)
predictTest = predict(framinghamLog, type="response", newdata = test)
table(test$TenYearCHD, predictTest > 0.5)
(1069+11) / (1069+11+6+187)
(1069+6) / (1069+11+6+187)
library(ROCR)
ROCRpred = prediction(predictTest, test$TenYearCHD)
as.numeric(performance(ROCRpred, "auc")@y.values)
polling = read.csv("PollingData.csv")
str(polling)
summary(polling)
# Let's deal with the missing values
install.packages("mice")
# Let's deal with the missing values
# install.packages("mice")
library(mice)
simple = polling[c("Rasmussen","SurveyUSA","DiffCount","PropR")]
summary(simple)
set.seed(144)
imputed = complete(mice(simple))
summary(imputed)
imputed = complete(mice(simple))
# Copy back to the initial dataframe
polling$Rasmussen = imputed$Rasmussen
polling$SurveyUSA = imputed$SurveyUSA
# Check
summary(polling)
train = subset(polling,Year == 2004 | Year == 2008)
test = subset(polling, Year == 2012)
# Baseline model
table(train$Republican)
# Smarter baseline model using Rasmussen
sign(train$Rasmussen)
# Smarter baseline model using Rasmussen
table(sign(train$Rasmussen))
# Smarter baseline model using Rasmussen
table(sign(train$Rasmussen), train$Republican)
# Smarter baseline model using Rasmussen
table(train$Republican, sign(train$Rasmussen))
# Check for multicollinearity
cor(train)
# Check for multicollinearity
cor(train[c("Rasmussen","SurveyUSA","DiffCount","PropR")])
# Check for multicollinearity
cor(train[c("Rasmussen","SurveyUSA","DiffCount","PropR","Republican")])
# Build a model with only single dependent variable
mod1 = glm(Republican ~ PropR, data = train, family = binomial)
summary(mod1)
pred1 = predict(mod1, type="response")
table(train$Republican, pred1 > 0.5)
table(train$Republican, pred1 > 0.5) # Make four mistakes. Can we include by adding new variables?
mod2 = glm(Republican ~ SurveyUSA + DiffCount, data = train, family = binomial)
summary(mod2)
pred2 = predict(mod2, type="response")
table(train$Republican, pred2 > 0.5)
summary(mod2)
table(test$Republican, sign(test$Rasmussen)) # The smart baseline method
predTest = predict(mod2, newdata = test, type = "response")
table(test$Republican, predTest > 0.5)
# Pull out to see why the prediction is wrong.
table(test, predTest >= 0.5 & test$Republican == 0)
# Pull out to see why the prediction is wrong.
table(test, predTest >= 0.5 & Republican == 0)
test$Republican
# Pull out to see why the prediction is wrong.
table(test, predTest >= 0.5 & Republican == 0)
# Pull out to see why the prediction is wrong.
table(test, predTest >= 0.5 & Republican == 0)
# Pull out to see why the prediction is wrong.
table(test, predTest >= 0.5 & Republican == 0)
test$Republican
# Pull out to see why the prediction is wrong.
table(test, predTest >= 0.5 & test$Republican == 0)
# Pull out to see why the prediction is wrong.
subset(test, predTest >= 0.5 & Republican == 0)
