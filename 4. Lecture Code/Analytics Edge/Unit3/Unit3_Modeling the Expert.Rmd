---
title: 'Unit3: Modeling the Expert'
output: pdf_document
---

```{r}
quality = read.csv("quality.csv")
str(quality)
```

```{r}
# install.packages("caTools")
library(caTools)
set.seed(88)
split = sample.split(quality$PoorCare, SplitRatio = 0.75) # Test set will be representative for the training set
qualityTrain = subset(quality, split == TRUE)
qualityTest = subset(quality, split == FALSE)
```

```{r}
# Let's build a logistic regression model in R
QualityLog = glm(PoorCare ~ OfficeVisits + Narcotics, data = qualityTrain, family = binomial)
summary(QualityLog)

# The preferred model is the one with minimum AIC.
```

```{r}
predictTrain = predict(QualityLog, type = "response") # type = "response" will output probabilities
summary(predictTrain)
```

```{r}
tapply(predictTrain, qualityTrain$PoorCare, mean)
```


```{r}
table(qualityTrain$PoorCare, predictTrain > 0.5) # A confusion matrix for true outcome (rows) and predicted outcome (columns)

# Sensitivity = 10 / 25 = 0.4
# Specificity = 70 / 74 = 0.95
```


```{r}
table(qualityTrain$PoorCare, predictTrain > 0.7) # A confusion matrix for true outcome (rows) and predicted outcome (columns)

# Sensitivity = 8 / 25 = 0.32
# Specificity = 73 / 74 = 0.99
```

```{r}
# install.packages("ROCR")
library(ROCR)
ROCRpred = prediction(predictTrain, qualityTrain$PoorCare)
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf, colorize = TRUE, print.cutoffs.at = seq(0,1,0.1), text.adj = c(-0.2, 1.7))
```

```{r}
predictTest = predict(QualityLog, type = "response", newdata = qualityTest)
table(qualityTest$PoorCare, predictTest > 0.3) # A confusion matrix for true outcome (rows) and predicted outcome (columns)

```

```{r}
# Let's compute the AUC score
ROCpredTest = prediction(predictTest, qualityTest$PoorCare)
auc = as.numeric(performance(ROCpredTest, "auc")@y.values)
auc
plot(performance(ROCpredTest, "tpr", "fpr"))
```

